{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZgGNXZEfywz"
   },
   "source": [
    "#Task 1: Tokenization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deLPHwbIX3-r"
   },
   "outputs": [],
   "source": [
    "# Download Gutenberg Corpus\n",
    "# It is the dataset on which this model will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08q0ospof2z9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import operator as op\n",
    "from math import log\n",
    "from functools import reduce\n",
    "\n",
    "from ipy_table import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "corpus_directory = 'Gutenberg/txt'\n",
    "\n",
    "corpus = []\n",
    "sentences = []\n",
    "words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(text):\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,?!.\\/'+=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" , \", text)\n",
    "    text = re.sub(r\"\\.\", \" . \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\?\", \" ? \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(sentence):\n",
    "    sentence = clean_sentence(sentence).split()\n",
    "    sentences.append(sentence)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def tokenise_corpus(corpus):\n",
    "    # Convert byte object to string\n",
    "    corpus = corpus.decode(\"utf-8\")\n",
    "\n",
    "    # Remove all new line characters, as they may be at abrupt places.\n",
    "    # Also change case to lower.\n",
    "    corpus = re.sub(r'\\n', \" \", corpus).lower()\n",
    "\n",
    "    # Place new line characters at the end of sentences.\n",
    "    # Ignoring abbreviations for the sake of simplicity.\n",
    "    corpus = re.sub(r\"([.!?])\", r\"\\1\\n\", corpus)\n",
    "\n",
    "    # Split corpus into sentences.\n",
    "    corpus = corpus.split('\\n')\n",
    "\n",
    "    return [tokenise(sentence) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain list of all files in Gutenberg Corpus.\n",
    "files = os.listdir(corpus_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data from all files in Gutenberg Corpus.\n",
    "for file in files[:5]:\n",
    "    with open(os.path.join(corpus_directory, file), 'rb') as f:\n",
    "        contents = f.read()\n",
    "        corpus += tokenise_corpus(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cell, loads data only from first file.\n",
    "# with open(os.path.join(corpus_directory, files[0]), 'rb') as f:\n",
    "#     contents = f.read()\n",
    "#     corpus += tokenise_corpus(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a count of all unique words in the corpus \n",
    "def token_counts(corpus):\n",
    "    tokens = {}\n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            if word not in tokens:\n",
    "                tokens[word] = 0\n",
    "            tokens[word] += 1\n",
    "    return tokens\n",
    "\n",
    "tokens = token_counts(corpus)\n",
    "sorted_tokens = sorted(tokens.items(), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "frequencies = []\n",
    "\n",
    "for pair in sorted_tokens:\n",
    "    words.append(pair[0])\n",
    "    frequencies.append(pair[1])\n",
    "\n",
    "# Create a trace\n",
    "trace = go.Scatter(\n",
    "    x = words,\n",
    "    y = frequencies\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "iplot(data, filename='basic-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gwBEe5bgAbn"
   },
   "source": [
    "#Language Model and Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(object):\n",
    "    def __init__(self, units, n=4):\n",
    "        self.units = units\n",
    "        self.n = n\n",
    "        self.n_grams = [{}]\n",
    "        self.vocab_size = [0]\n",
    "        self.seen_counts = [0]\n",
    "\n",
    "    def ncr(self, n, r):\n",
    "        r = min(r, n-r)\n",
    "        numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "        denom = reduce(op.mul, range(1, r+1), 1)\n",
    "        return numer//denom\n",
    "\n",
    "    def get_n_grams(self, n):\n",
    "        n_grams = {}\n",
    "\n",
    "        for unit in self.units:\n",
    "            unit_len = len(unit)\n",
    "\n",
    "            for i in range(unit_len - n):\n",
    "                n_gram = tuple(unit[i:i+n])\n",
    "                if n_gram not in n_grams:\n",
    "                    n_grams[n_gram] = 0\n",
    "                n_grams[n_gram] += 1\n",
    "\n",
    "        if n == 1: self.vocab_size.append(len(n_grams))\n",
    "        else: self.vocab_size.append(self.ncr(self.vocab_size[1], n-1))\n",
    "\n",
    "        self.n_grams.append(n_grams)\n",
    "        self.seen_counts.append(len(n_grams))\n",
    "\n",
    "    def get_sorted_n_grams(self, n):\n",
    "        if n > self.n:\n",
    "            print('Max permitted value of n is:', self.n)\n",
    "            return\n",
    "\n",
    "        return sorted(self.n_grams[n].items(), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "    def split_grams_freq(self, sorted_n_grams):\n",
    "        n_grams = []\n",
    "        frequencies = []\n",
    "\n",
    "        for pair in sorted_n_grams:\n",
    "            # n-grams are in the form of tuples for the sake of simplicity.\n",
    "            if isinstance(pair[0], tuple):\n",
    "                n_grams.append(' '.join(pair[0]))\n",
    "\n",
    "            frequencies.append(pair[1])\n",
    "        \n",
    "        return n_grams, frequencies\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(1, self.n+1):\n",
    "            self.get_n_grams(i)\n",
    "\n",
    "    def plot_graph(self, n_grams, frequencies, topk=None, loglog=False):\n",
    "        if loglog:\n",
    "            n_grams = [i for i in range(len(frequencies))]\n",
    "            layout = dict(title = 'Frequency counts of various n-grams',\n",
    "                          xaxis = dict(title = 'n-grams', type='log'),\n",
    "                          yaxis = dict(title = 'frequency', type='log'))\n",
    "        else:\n",
    "            layout = dict(title = 'Frequency counts of various n-grams',\n",
    "                          xaxis = dict(title = 'n-grams'),\n",
    "                          yaxis = dict(title = 'frequency'))\n",
    "\n",
    "        # Create a trace\n",
    "        trace = go.Scatter(\n",
    "            x = n_grams[:topk],\n",
    "            y = frequencies[:topk],\n",
    "            name = 'n grams',\n",
    "            line = dict(color = ('rgb(205, 12, 24)'),\n",
    "                        width = 4))\n",
    "\n",
    "        data = [trace]\n",
    "\n",
    "        fig = dict(data=data, layout=layout)\n",
    "        iplot(fig, filename='styled-line')\n",
    "\n",
    "    '''\n",
    "    Plot ngrams in the descending order of frequency\n",
    "    '''\n",
    "    def plot_n_gram_freqs(self, n, topk=None, loglog=False):\n",
    "        if n > self.n:\n",
    "            print('Max permitted value of n is:', self.n)\n",
    "            return\n",
    "\n",
    "        sorted_n_grams = self.get_sorted_n_grams(n)\n",
    "        n_grams, frequencies = self.split_grams_freq(sorted_n_grams)\n",
    "\n",
    "        self.plot_graph(n_grams, frequencies, topk, loglog=loglog)\n",
    "\n",
    "    '''\n",
    "    Given (N-1) gram, and the value 'N',\n",
    "        1. Print the possibilities that complete the n-gram\n",
    "        2. Plot them in decresing order of frequency\n",
    "    '''\n",
    "    def complete_ngram(self, n_gram, n, topk=None):\n",
    "        if n > self.n:\n",
    "            print('Max permitted value of n is:', self.n)\n",
    "            return\n",
    "\n",
    "        if not isinstance(n_gram, tuple):\n",
    "            if isinstance(n_gram, str):\n",
    "                n_gram = n_gram.split()\n",
    "\n",
    "            n_gram = tuple(n_gram)\n",
    "\n",
    "        sorted_n_grams = self.get_sorted_n_grams(n)\n",
    "\n",
    "        n_grams = []\n",
    "        frequencies = []\n",
    "\n",
    "        for pair in sorted_n_grams:\n",
    "            if n_gram == pair[0][:n-1]:\n",
    "                n_grams.append(' '.join(pair[0]))\n",
    "                frequencies.append(pair[1])\n",
    "\n",
    "        for i in range(min(10, len(n_grams))):\n",
    "            print(n_grams[i], frequencies[i])\n",
    "\n",
    "        self.plot_graph(n_grams, frequencies, topk)\n",
    "\n",
    "    def laplace_smoothing(self, n_grams, alpha=0.001):\n",
    "        n = len(n_grams[0])\n",
    "        score = 1\n",
    "\n",
    "        for n_gram in n_grams:\n",
    "            # Numerator of the score\n",
    "            count_n = alpha\n",
    "            if n_gram in self.n_grams[n]: count_n += self.n_grams[n][n_gram]\n",
    "\n",
    "            # Denominator of the score\n",
    "            count_d = alpha*self.vocab_size[n]\n",
    "            if n_gram[:-1] in self.n_grams[n-1]: count_d += self.n_grams[n-1][n_gram[:-1]]\n",
    "\n",
    "            '''\n",
    "            Uncomment the line below to view the disparity in data.\n",
    "            Most of the possiblen-grams are never seen in corpus.\n",
    "            '''\n",
    "            # print(count_n, count_d - alpha*self.vocab_size[n], self.vocab_size[n])\n",
    "            score *= (count_n/count_d)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def backoff(self, scores):\n",
    "        weights = [[1],\n",
    "                   [0.39, 0.61],\n",
    "                   [0.025, 0.275, 0.700]]\n",
    "\n",
    "        ind = len(scores)-1\n",
    "        return [sum([a*b for a, b in zip(weights[ind], scores)])]\n",
    "\n",
    "    def kneser_ney(self, n_grams, delta=0.5, epsilon=1e-7):\n",
    "        n = len(n_grams[0])\n",
    "        score = 1\n",
    "\n",
    "        for n_gram in n_grams:\n",
    "            # Numerator of the score\n",
    "            count_n = 0\n",
    "            if n_gram in self.n_grams[n]: count_n += self.n_grams[n][n_gram] - delta\n",
    "\n",
    "            # Denominator of the score\n",
    "            count_d = 0\n",
    "            pwi = 0\n",
    "            for key in self.n_grams[n].keys():\n",
    "                if n_gram[:-1] == key[:-1]:\n",
    "                    count_d += self.n_grams[n][key]\n",
    "\n",
    "                if n_gram[-1] == key[-1]:\n",
    "                    pwi += self.n_grams[n][key]\n",
    "\n",
    "            if count_d == 0:\n",
    "                return 0\n",
    "\n",
    "            pwi /= self.seen_counts[n]\n",
    "            lambdai = delta/count_d\n",
    "            # print(pwi, lambdai, count_n)\n",
    "\n",
    "            score *= ((count_n/count_d) + pwi*lambdai + epsilon)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def score_sequence(self, sequence, alpha=0.001, scoring_function='laplace_smoothing', backoff=False):\n",
    "        seq_len = len(sequence)\n",
    "\n",
    "        combined_n_grams = []\n",
    "        scores = []\n",
    "\n",
    "        for n in range(1, self.n+1):\n",
    "            n_grams = []\n",
    "\n",
    "            for i in range(seq_len-n+1):\n",
    "                n_grams.append(tuple(sequence[i:i+n]))\n",
    "                if i == seq_len-n:\n",
    "                    break\n",
    "\n",
    "            if len(n_grams) > 0: combined_n_grams.append(n_grams)\n",
    "\n",
    "        # Only giving bigrams and above to scoring functions\n",
    "        for n_grams in combined_n_grams[1:]:\n",
    "            if scoring_function == 'laplace_smoothing':\n",
    "                scores.append(self.laplace_smoothing(n_grams, alpha=alpha))\n",
    "\n",
    "            elif scoring_function == 'kneser_ney':\n",
    "                scores.append(self.kneser_ney(n_grams))\n",
    "                if scores[-1] == 0:\n",
    "                    break\n",
    "\n",
    "                scores = [scores[-1]]\n",
    "\n",
    "        if backoff: scores = self.backoff(scores)\n",
    "\n",
    "        return sum(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjoF5Wlsaf_M"
   },
   "source": [
    "#Task 2: Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Character Level Language Model\n",
    "class CharLM(LanguageModel):\n",
    "    def __init__(self, units, n=4):\n",
    "        LanguageModel.__init__(self, units, n)\n",
    "\n",
    "    def suggest_spelling(self, word):\n",
    "        suggestions = {}\n",
    "        suggestions[word] = self.score_sequence(word)\n",
    "\n",
    "        word = list(word)\n",
    "        length = len(word)\n",
    "\n",
    "        def insert(suggestions, word, score):\n",
    "            if word not in suggestions:\n",
    "                if len(suggestions) < 10:\n",
    "                    suggestions[word] = score\n",
    "                else:\n",
    "                    min_key = min(suggestions, key=suggestions.get)\n",
    "                    if score > suggestions[min_key]:\n",
    "                        del suggestions[min_key]\n",
    "                        suggestions[word] = score\n",
    "\n",
    "        for i in range(length):\n",
    "            # Remove one character\n",
    "            new_word_r = ''.join(word[:i] + word[i+1:])\n",
    "            score_r = self.score_sequence(new_word_r)\n",
    "\n",
    "            insert(suggestions, new_word_r, score_r)\n",
    "\n",
    "            for char in self.n_grams[1]:\n",
    "                # Add one character\n",
    "                new_word_a = ''.join(word[:i] + list(char) + word[i:])\n",
    "                score_a = self.score_sequence(new_word_a)\n",
    "\n",
    "                insert(suggestions, new_word_a, score_a)\n",
    "\n",
    "                # Swap one character\n",
    "                for j in range(length-1):\n",
    "                    new_word_r = list(new_word_r)\n",
    "                    new_word_s = ''.join(new_word_r[:j] + list(char) + new_word_r[j:])\n",
    "                    score_s = self.score_sequence(new_word_s)\n",
    "\n",
    "                    insert(suggestions, new_word_s, score_s)\n",
    "\n",
    "        if str(word) in suggestions: print('Your spelling\\'s perfect!')\n",
    "        else: print('Did you mean:\\n', [str(key) for key in suggestions.keys()])\n",
    "\n",
    "char_lm = CharLM(words, n=4)\n",
    "char_lm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unigram frequencies\n",
    "char_lm.plot_n_gram_freqs(2, topk=25)\n",
    "char_lm.plot_n_gram_freqs(2, topk=25, loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a correctness score to word spelling.\n",
    "sequence = 'hat'\n",
    "\n",
    "print('Laplace Smoothing                 :', char_lm.score_sequence(sequence))\n",
    "print('Laplace Smoothing with backoff    :', char_lm.score_sequence(sequence, backoff=True))\n",
    "print('Kneser Ney Smoothing              :', char_lm.score_sequence(sequence, scoring_function='kneser_ney'))\n",
    "\n",
    "print('\\n')\n",
    "if sequence not in words:\n",
    "    char_lm.suggest_spelling(sequence)\n",
    "print('\\n')\n",
    "\n",
    "sequence = 'phat'\n",
    "\n",
    "print('Laplace Smoothing                 :', char_lm.score_sequence(sequence))\n",
    "print('Laplace Smoothing with backoff    :', char_lm.score_sequence(sequence, backoff=True))\n",
    "print('Kneser Ney Smoothing              :', char_lm.score_sequence(sequence, scoring_function='kneser_ney'))\n",
    "\n",
    "print('\\n')\n",
    "if sequence not in words:\n",
    "    char_lm.suggest_spelling(sequence)\n",
    "print('\\n')\n",
    "\n",
    "# print(char_lm.seen_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgPpfeyYgLUv"
   },
   "source": [
    "#Task 3 : Grammaticality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Word Level Language Model\n",
    "class WordLM(LanguageModel):\n",
    "    def __init__(self, units, n=4):\n",
    "        LanguageModel.__init__(self, units, n)\n",
    "\n",
    "word_lm = WordLM(sentences, n=4)\n",
    "word_lm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n-gram frequencies\n",
    "word_lm.plot_n_gram_freqs(2)\n",
    "word_lm.plot_n_gram_freqs(2, loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lm.complete_ngram('and', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a correctness score to sentence grammaticality.\n",
    "sequence = 'I am a man.'\n",
    "\n",
    "sequence = tokenise(sequence.lower())\n",
    "print('Laplace Smoothing                 :', word_lm.score_sequence(sequence, alpha=0.00001))\n",
    "print('Laplace Smoothing with backoff    :', word_lm.score_sequence(sequence, alpha=0.00001, backoff=True))\n",
    "print('Kneser Ney Smoothing              :', word_lm.score_sequence(sequence, scoring_function='kneser_ney'))\n",
    "print('\\n')\n",
    "\n",
    "sequence = 'man I am a.'\n",
    "\n",
    "sequence = tokenise(sequence.lower())\n",
    "print('Laplace Smoothing                 :', word_lm.score_sequence(sequence, alpha=0.00001))\n",
    "print('Laplace Smoothing with backoff    :', word_lm.score_sequence(sequence, alpha=0.00001, backoff=True))\n",
    "print('Kneser Ney Smoothing              :', word_lm.score_sequence(sequence, scoring_function='kneser_ney'))\n",
    "print('\\n')\n",
    "\n",
    "# print(word_lm.seen_counts)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Error Correction Demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
